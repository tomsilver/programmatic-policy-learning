## System Prompt
You are an expert programmer and problem solver.
Your task is to write a correct and general policy in Python.
You may define helper functions if needed.
Return only executable Python code.

--

## Environment description:

- The environment is a grid world of the game 'ReachForTheStar'.
- The observation `obs` is a 2D Python NumPy array (rows × columns).
  - Do not use boolean checks such as `if obs`, `if not obs`, or `obs == []`. 
- Each cell contains exactly one of the following symbols:

  - 'empty'
  - 'agent'
  - 'star'
  - 'drawn'
  - 'left_arrow'
  - 'right_arrow'

- The agent occupies exactly one cell.
- The star occupies exactly one cell and represents the goal.
- Arrow cells provide directional cues that correlate with successful movement patterns.
- Drawn cells are part of the environment but do not represent the agent or the goal.

--

## Action space:

The policy must return a tuple (row, column) corresponding to a cell in the grid.

- (row, column) must be a valid cell location within the grid bounds.
- Selecting a cell represents choosing that cell as the agent’s action.
- The environment defines how selecting a cell affects the agent’s movement.
- Selecting an invalid or unreachable cell has no effect.


--

## Task Description
Task:
Guide the agent to reach the star cell.
The episode ends successfully when the agent reaches the star.

--

## Expert-Derived Hints

Below is a summary of patterns extracted from a set of expert trajectories. These are NOT DSL primitives, but they describe spatial relations frequently relevant to decision-making.

### High-frequency relational patterns:
- The agent consistently moves horizontally until it is aligned beneath the target (star) along the x-axis.
- The agent only begins to ascend (move vertically) after reaching a column directly below or nearly below the target.
- The agent constructs or utilizes a staircase-like structure to reach the vertical level of the target.

### Useful directional / asymmetry relations:
- The agent prioritizes reducing horizontal (x-axis) distance before addressing vertical (y-axis) distance.
- The agent’s movement is asymmetric: horizontal movement dominates until a specific x-position is reached, after which vertical movement becomes relevant.
- The agent always approaches the target from below, never from above or the sides.

### Example state–action correlations:
- When the agent is not vertically aligned with the target, the next action is a horizontal move toward the target’s x-coordinate.
- When the agent is vertically aligned (or nearly so) with the target, - the next action tends to move upward when such a move is possible.
- If there is an obstacle or gap below the target, the agent constructs or climbs a staircase structure to reach the target’s height.

### Frequently observed local spatial configurations:
- The agent is positioned directly below the target, separated by a vertical gap.
- There is a staircase or column of blocks leading from the agent’s position up to the target.
- The agent is always on a solid surface (never floating), and the staircase is contiguous from the ground to the target’s level.

### Observed distance thresholds or step ranges:
- The agent begins vertical movement when the horizontal distance to the target is zero or within one cell.
- The staircase height matches the vertical distance between the agent’s ground level and the target’s position.
- The agent does not attempt to ascend until the horizontal offset is minimized (distance ≤ 1 cell).
- The agent never moves more than one cell away from the staircase or supporting structure while ascending.

--

## Output Format Constraint

Return ONLY the Python code for the policy, wrapped in a Markdown fenced code block
that starts with ```python and ends with ```.

The code must define a function with the following signature:

```python
def policy(obs):
    ...
    return action
```

Where `action` is either:
- a tuple (row, col), or
- None if no valid move exists.

You may define helper functions inside the code.
Do not use external libraries.
Do not include explanations, comments, or markdown.
Return only executable Python code.
Do not include any text outside the code block.

--

## Notes on ReachForTheStar Assumptions 

- No ReachForTheStar-specific helper functions are provided.
- The policy must infer the agent and target locations directly from the grid observation.
- Arrow cells are treated as directional cues but do not correspond to explicit actions.
- The policy does not have access to the environment’s transition dynamics.
- All movement and interaction semantics are defined by the environment.
